{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pytensor as pt\n",
    "import pytensor.tensor as ptt\n",
    "\n",
    "import icomo\n",
    "from icomo import jax2pytensor\n",
    "\n",
    "plt.rcParams.update({'font.size': 8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_confidence_interval(data, n=1000, func=np.mean, alpha=0.05):\n",
    "    resamples = np.random.choice(data.dropna(), size=(n, len(data.dropna())), replace=True)\n",
    "    perc = np.percentile([func(r) for r in resamples], [100*alpha/2, 100*(1-alpha/2)])\n",
    "    return [func(data.dropna()) - perc[0], perc[1] - func(data.dropna())]\n",
    "\n",
    "def percentile_confidence_interval(data, alpha=0.05):\n",
    "    perc = np.percentile(data.dropna(), [100*alpha/2, 100*(1-alpha/2)])\n",
    "    return [data.mean() - perc[0], perc[1] - data.mean()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps = 30\n",
    "dt = 1.0 / pps\n",
    "\n",
    "# standard parameters\n",
    "# activation is b + sum kappa t_spike with kappa = kernel0 * dt^-alpha\n",
    "# parameters from model fit\n",
    "_b = -0.7\n",
    "_alpha = 0.3\n",
    "_kappa0 = 0.1\n",
    "_cutoff = 120.0 # [s]\n",
    "\n",
    "def create_kernel(alpha, kappa0, cutoff, pps):\n",
    "    dt = 1.0 / pps\n",
    "    t = np.arange(dt, cutoff*4, dt)\n",
    "    # kappa = kappa0 * np.power(t, -alpha) / pps\n",
    "    kappa = np.zeros_like(t)\n",
    "    kappa = kappa0 * np.power(t, -alpha) / pps\n",
    "    kappa *= np.exp(-t/cutoff)\n",
    "    return kappa, t\n",
    "\n",
    "def _kappa(dt, pps):\n",
    "    return _kappa0 * np.power(dt, -_alpha) / pps\n",
    "\n",
    "kappa, t = create_kernel(_alpha, _kappa0, _cutoff, pps)\n",
    "\n",
    "fig = plt.figure(figsize=(6.5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "dts = np.logspace(-2, 3, 100)\n",
    "ax.plot(dts, [_kappa(dt, pps) for dt in dts], label=r'${:2f} t^{{-{:2f}}}$'.format(_kappa0,_alpha), color='blue')\n",
    "ax.plot(t, kappa, label='kernel', color='red')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Kappa')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the differential equations\n",
    "def get_release_rate(ts, args):\n",
    "\n",
    "    t_args, const_args = args\n",
    "\n",
    "    B = const_args[\"B\"]\n",
    "    ALPHA = const_args[\"ALPHA\"]\n",
    "    KAPPA0 = const_args[\"KAPPA0\"]\n",
    "    CUTOFF = const_args[\"CUTOFF\"]\n",
    "\n",
    "    kappa, _ = create_kernel(ALPHA, KAPPA0, CUTOFF, pps)\n",
    "    kappa = np.flip(kappa)\n",
    "    print(kappa)\n",
    "\n",
    "    stim_rate = t_args\n",
    "\n",
    "    releases = np.zeros(len(ts)+len(kappa))\n",
    "    activations = np.zeros(len(ts))\n",
    "    k_length = len(kappa)\n",
    "    for ind_t, t in enumerate(ts):\n",
    "\n",
    "        # recovery\n",
    "        recovery = np.sum(releases[ind_t:ind_t+k_length] * kappa)\n",
    "\n",
    "        # release\n",
    "        a = B - recovery\n",
    "        activations[ind_t] = a\n",
    "\n",
    "        p = np.exp(a)/(1 + np.exp(a))\n",
    "        release_rate = - p**4 + 4*p**3 - 6*p**2 + 4*p\n",
    "        releases[ind_t+k_length] = release_rate * stim_rate[ind_t]\n",
    "    releases = releases[k_length:]\n",
    "    return releases, activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sim = 10 * 60 # s\n",
    "num_points = int(len_sim * pps) \n",
    "\n",
    "### First set the time variables\n",
    "t = jnp.linspace(0, len_sim, num_points) # timepoints at which the ODE is solved\n",
    "t_stim = t # timepoints at which the stimulus is defined\n",
    "t_out = t # timepoints at which the output is saved\n",
    "\n",
    "### Set parameters\n",
    "stim = 50 * jnp.ones(len(t_stim))\n",
    "# stim = np.logical_or(t_stim < 2, t_stim > 22) * stim\n",
    "t_args = stim\n",
    "\n",
    "const_args = {\n",
    "    \"ALPHA\": _alpha,\n",
    "    \"B\": _b,\n",
    "    \"KAPPA0\": _kappa0,\n",
    "    \"CUTOFF\": _cutoff,\n",
    "}\n",
    "\n",
    "# get the release rate\n",
    "release_rate, activations = get_release_rate(t, (t_args, const_args))\n",
    "print(release_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool sizes\n",
    "f = plt.figure(figsize=(3*2.5,1.8))\n",
    "axs = f.subplots(1,3)\n",
    "\n",
    "# compare discrete and continuous release\n",
    "filename = \"../fig2/depression_test_50Hz.h5\"\n",
    "dic = h5py.File(filename, 'r')\n",
    "\n",
    "ves_per_spike = dic.get('ves_per_spike')[()] \n",
    "ves_per_spike_mean = np.mean(ves_per_spike, axis=1)\n",
    "ps = dic.get('ps')[()]\n",
    "sizes = dic.get('sizes')[()]\n",
    "test_times = dic.get('test_times')[()]\n",
    "\n",
    "i_p = np.where(ps == 0.2)[0][0]\n",
    "i_size = np.where(sizes == 1.0)[0][0]\n",
    "sim_data = ves_per_spike_mean[:,i_p,i_size]\n",
    "\n",
    "ves_per_spike = release_rate / stim\n",
    "\n",
    "axs[0].plot(test_times, sim_data,\n",
    "    linestyle='None', marker='o', zorder=2, markersize=2.0, label=\"discrete model\", \n",
    "    color='cornflowerblue')\n",
    "axs[0].plot(t_out, ves_per_spike, label=\"continuous model\")\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[0].set_xscale(\"log\")\n",
    "axs[0].set_xlabel(\"Time [s]\")\n",
    "axs[0].set_ylabel(\"Ves. per spike\");\n",
    "# remove top and right spines\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "\n",
    "# compare discrete and continuous release regular scale\n",
    "axs[1].plot(test_times, sim_data,\n",
    "    linestyle='None', marker='o', zorder=2, markersize=2.0, label=\"full model\", \n",
    "    color='cornflowerblue')\n",
    "inds = np.where(t_out <= 200)[0]\n",
    "axs[1].plot(t_out[inds], ves_per_spike[inds], label=\"power-law GLM\")\n",
    "axs[1].legend(frameon=False)\n",
    "axs[1].set_xlabel(\"Time [s]\")\n",
    "axs[1].set_ylabel(\"Ves. per spike\");\n",
    "axs[1].set_xlim([-2,50])\n",
    "# remove top and right spines\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "\n",
    "# show recovery\n",
    "axs[2].plot(t_out, activations)\n",
    "# axs[2].plot(t_out, y)\n",
    "axs[2].set_xlabel(\"Time [s]\")\n",
    "axs[2].set_ylabel(\"Activation\")\n",
    "axs[2].set_xlim([-2,50])\n",
    "# axs[2].set_yscale(\"log\")\n",
    "# remove top and right spines\n",
    "axs[2].spines['top'].set_visible(False)\n",
    "axs[2].spines['right'].set_visible(False)\n",
    "\n",
    "f.tight_layout()\n",
    "f.savefig(\"discrete_GLM_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get experimental data\n",
    "excel_file = \"exp1_data.xlsx\" # change path to the location of your file\n",
    "df1 = pd.read_excel(excel_file)\n",
    "\n",
    "# load exhaustion experiment data from xls\n",
    "excel_file = \"exp2_data.xlsx\" \n",
    "df2 = pd.read_excel(excel_file)\n",
    "data2 = df2[df2.columns[1:]].values.T\n",
    "time = df2[\"seconds\"].values\n",
    "print(data2.shape)\n",
    "print(time.shape)\n",
    "experimental_fusion_rate = np.diff(data2) / np.diff(time)\n",
    "experimental_fusion_rate = np.concatenate([experimental_fusion_rate, np.zeros((experimental_fusion_rate.shape[0],1))], axis=1)\n",
    "print(experimental_fusion_rate.shape)\n",
    "\n",
    "# stim starts at 32.35 s\n",
    "stim_start = 32.35\n",
    "inds = time > stim_start\n",
    "time = time[inds] - time[inds][0]\n",
    "data2 = data2[:,inds]\n",
    "# start at 0 not 1\n",
    "data2 = data2 - data2[:,[0]]\n",
    "experimental_fusion_rate = experimental_fusion_rate[:,inds]\n",
    "print(data2.shape)\n",
    "print(time.shape)\n",
    "\n",
    "data2_means = np.mean(data2, axis=0)\n",
    "data2_errs = np.std(data2, axis=0) / np.sqrt(data2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptt_create_kernel(alpha, kappa0, cutoff, pps):\n",
    "    dt = 1.0 / pps\n",
    "    t = np.arange(dt, cutoff, dt)\n",
    "    kappa = kappa0 * ptt.power(t, -alpha) / pps\n",
    "    # for efficiency we ignore the exp. cutoff and just shorten the kernel\n",
    "    kappa *= np.exp(-t/cutoff) \n",
    "    return kappa\n",
    "\n",
    "# Define the differential equations\n",
    "def get_release_rate_pymc(pps, args):\n",
    "\n",
    "    t_args, const_args = args\n",
    "\n",
    "    B = const_args[\"B\"]\n",
    "    ALPHA = const_args[\"ALPHA\"]\n",
    "    KAPPA0 = const_args[\"KAPPA0\"]\n",
    "    CUTOFF = const_args[\"CUTOFF\"]\n",
    "\n",
    "    kappa = ptt_create_kernel(ALPHA, KAPPA0, CUTOFF, pps)\n",
    "    dt = 1.0 / pps\n",
    "    len_kappa = len(np.arange(dt, CUTOFF, dt))\n",
    "\n",
    "    stim_rate = t_args\n",
    "\n",
    "    releases = ptt.zeros(len_kappa)\n",
    "    def update_releases(stim_rate, releases, kappa, B):\n",
    "        # recovery\n",
    "        recovery = ptt.sum(releases * kappa)\n",
    "        # release\n",
    "        a = B - recovery\n",
    "        p = ptt.exp(a)/(1 + ptt.exp(a)) \n",
    "        release_rate = - p**4 + 4*p**3 - 6*p**2 + 4*p\n",
    "        release = release_rate * stim_rate\n",
    "\n",
    "        rolled_releases = ptt.roll(releases, 1)\n",
    "        updated_releases = ptt.set_subtensor(rolled_releases[0], release)\n",
    "        return updated_releases\n",
    "    \n",
    "    outputs, _ = pt.scan(\n",
    "        fn=update_releases, \n",
    "        sequences=[stim_rate], \n",
    "        non_sequences=[kappa, B],\n",
    "        outputs_info=releases)\n",
    "\n",
    "    releases = outputs[:,0]\n",
    "\n",
    "    return releases\n",
    "\n",
    "def run_experiment1(stim_rate, depletiontime, pausetime, testtime, const_args):\n",
    "    pps = 10\n",
    "    len_sim = depletiontime + pausetime + testtime\n",
    "    num_points = int(len_sim * pps) + 1\n",
    "\n",
    "    ### First set the time variables\n",
    "    t = np.linspace(0, len_sim, num_points) \n",
    "    t_stim = t # timepoints at which the stimulus is defined\n",
    "    t_out_inds = np.logical_and((t > depletiontime + pausetime), (t < depletiontime + pausetime + testtime))\n",
    "\n",
    "    # define stimulus\n",
    "    stim = t_stim < depletiontime\n",
    "    stim = stim + (t_stim > depletiontime + pausetime)\n",
    "    stim = stim * stim_rate\n",
    "    t_args = stim\n",
    "\n",
    "    # get the release rate\n",
    "    release_rate = get_release_rate_pymc(pps, (t_args, const_args))\n",
    "    return release_rate[t_out_inds]\n",
    "\n",
    "def run_experiment2(stim_rate, const_args):\n",
    "    len_sim = 70 # s\n",
    "    pps_factor = 10\n",
    "    pps = pps_factor*1.7 # points per second later scaled to 1.7 by taking mod 10\n",
    "    num_points = int(len_sim * pps) + 1\n",
    "\n",
    "    ### First set the time variables\n",
    "    t = np.linspace(0, len_sim, num_points) \n",
    "    t_stim = t # timepoints at which the stimulus is defined\n",
    "    t_out_inds = (np.arange(len(t)) % pps_factor == 0) & (t <= time[-1])\n",
    "    \n",
    "    # define stimulus\n",
    "    stim = stim_rate * np.ones(len(t_stim))\n",
    "    t_args = stim\n",
    "\n",
    "    # get the release rate\n",
    "    release_rate = get_release_rate_pymc(pps, (t_args, const_args))\n",
    "    return release_rate[t_out_inds]\n",
    "\n",
    "def get_lognormal_params(mean, std):\n",
    "    sigma = np.sqrt(np.log(std**2 / mean**2 + 1))\n",
    "    mu = np.log(mean) - 0.5 * sigma**2\n",
    "    return mu, sigma\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    # Priors on the model parameters\n",
    "    alpha = 0.3\n",
    "    cutoff = _cutoff\n",
    "\n",
    "    # informative priors for better convergence\n",
    "    b1 = pm.Normal(\"b1\", mu=20, sigma=20)\n",
    "    mu, sigma = get_lognormal_params(12, 12)\n",
    "    kappa01 = pm.LogNormal(\"kappa01\", mu=mu, sigma=sigma)\n",
    "    observation_factor1 = pm.HalfCauchy(\"observation_factor1\", beta=0.01)#pm.HalfFlat(\"observation_factor1\") #\n",
    "\n",
    "    b2 = pm.Normal(\"b2\", mu=-1.5, sigma=3)\n",
    "    mu, sigma = get_lognormal_params(3e-08, 3e-08)\n",
    "    kappa02 = pm.LogNormal(\"kappa02\", mu=mu, sigma=sigma)\n",
    "    observation_factor2 = pm.HalfCauchy(\"observation_factor2\", beta=0.1) \n",
    "\n",
    "    error_model = pm.HalfCauchy(\"error_model\", beta=0.2)\n",
    "    mu, sigma = get_lognormal_params(error_model, error_model/4)\n",
    "    error_model1 = pm.LogNormal(\"error_model1\", mu=mu, sigma=sigma)\n",
    "    error_model2 = pm.LogNormal(\"error_model2\", mu=mu, sigma=sigma)\n",
    "\n",
    "\n",
    "    const_args_var1 = {\n",
    "        \"B\": b1,\n",
    "        \"ALPHA\": alpha,\n",
    "        \"KAPPA0\": kappa01,\n",
    "        \"CUTOFF\": cutoff,\n",
    "    }\n",
    "\n",
    "    testtime = 2.0 # s\n",
    "    depletiontimes = [0.4, 4.0, 40.0]\n",
    "    pausetimes = [1.0, 10.0, 40.0, 100.0]\n",
    "    stim_rate = 20.0 # Hz\n",
    "    conditions = [(depletiontime, pausetime) for pausetime in pausetimes for depletiontime in depletiontimes]\n",
    "    conditions.append((40.0, 200.0))\n",
    "\n",
    "    sim = []\n",
    "    sim_error = []\n",
    "    obs = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        depletiontime, pausetime = condition\n",
    "        # get condition name\n",
    "        fm = lambda x: round(x, 1) if x % 1 else int(x)\n",
    "        condition_name = \"{}_{}\".format(fm(depletiontime), fm(pausetime))\n",
    "        \n",
    "        release_rate = run_experiment1(stim_rate, depletiontime, pausetime, testtime, const_args_var1)\n",
    "        released = pm.math.mean(release_rate)\n",
    "\n",
    "        # save sim data under condition name\n",
    "        pm.Deterministic(condition_name, observation_factor1 * released)\n",
    "\n",
    "        # get data and simulation results\n",
    "        data = df1[condition_name]\n",
    "        error_of_the_mean = np.std(data) / np.sqrt(len(data))\n",
    "        data_mean = np.mean(data)\n",
    "        sigma_error = pm.Deterministic(\"scaled_sigma_error_\" + condition_name, error_model1 + error_of_the_mean)\n",
    "        \n",
    "        sim.append(observation_factor1 * released)\n",
    "        sim_error.append(sigma_error)\n",
    "        obs.append(data_mean)\n",
    "\n",
    "    sim = pm.math.stack(sim)\n",
    "    sim_error = pm.math.stack(sim_error)\n",
    "    \n",
    "    mu1 = sim\n",
    "    sigma1 = sim_error\n",
    "    observed1 = obs\n",
    "\n",
    "    ###### experiment 2\n",
    "\n",
    "    const_args_var2 = {\n",
    "        \"B\": b2,\n",
    "        \"ALPHA\": alpha,\n",
    "        \"KAPPA0\": kappa02,\n",
    "        \"CUTOFF\": cutoff,\n",
    "    }\n",
    "    \n",
    "    stim_rate = 5.0 # Hz\n",
    "    max_vesicles = 100\n",
    "\n",
    "    release_rate = run_experiment2(stim_rate, const_args_var2)\n",
    "    pps_experiment = 1.7\n",
    "    fused = release_rate / pps_experiment\n",
    "    # define ft = 1 - #tagged vesicles / #total vesicles\n",
    "    inv_rel_fraction = 1 - fused / max_vesicles\n",
    "    # then we can compute with cumprod the fraction of tagged vesicles\n",
    "    ft = pm.math.cumprod(inv_rel_fraction)\n",
    "    tagged = max_vesicles * (1 - ft)\n",
    "    tagged = tagged - tagged[0]\n",
    "\n",
    "    out = pm.Deterministic(\"experiment2\", observation_factor2 * tagged)\n",
    "    sim2_errors = pm.Deterministic(\"scaled_sigma_error_experiment2\", error_model2 + data2_errs)\n",
    "\n",
    "    mu2 = out\n",
    "    sigma2 = sim2_errors\n",
    "    observed2 = data2_means\n",
    "\n",
    "    observed = np.concatenate([observed1, observed2])\n",
    "    mu = ptt.concatenate([mu1, mu2])\n",
    "    sigma = ptt.concatenate([sigma1, sigma2])\n",
    "\n",
    "    def logp(observed, mu, sigma):\n",
    "        n = 13\n",
    "\n",
    "        observed1 = observed[:n]\n",
    "        observed2 = observed[n:]\n",
    "        mu1 = mu[:n]\n",
    "        mu2 = mu[n:]\n",
    "        sigma1 = sigma[:n]\n",
    "        sigma2 = sigma[n:]\n",
    "        p1 = pm.logp(pm.Normal.dist(mu1, sigma1),observed1)\n",
    "        p2 = pm.logp(pm.Normal.dist(mu2, sigma2),observed2)\n",
    "        return ptt.concatenate([p1, p2])\n",
    "\n",
    "    pm.CustomDist(\"likelihood\",\n",
    "                    mu, sigma,\n",
    "                    logp = logp,\n",
    "                    observed = observed)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate = pm.find_MAP(model=model)\n",
    "print(map_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the posterior\n",
    "sim_df = pd.DataFrame()\n",
    "for condition in conditions:\n",
    "    depletiontime, pausetime = condition\n",
    "    condition_name = \"{}_{}\".format(fm(depletiontime), fm(pausetime))\n",
    "    sim_df[condition_name] = np.array([map_estimate[condition_name]])\n",
    "\n",
    "fig = plt.figure(figsize=(3.5,2.8))\n",
    "ax = fig.subplots(1,1)\n",
    "\n",
    "# offset points\n",
    "import matplotlib.transforms as transforms\n",
    "offset = lambda p: transforms.ScaledTranslation(p/72.,0, fig.dpi_scale_trans)\n",
    "trans = ax.transData\n",
    "\n",
    "# remove the right and top and bottom spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "errs_df = df1.apply(lambda x: bootstrap_confidence_interval(x), axis=0)\n",
    "plt.errorbar(df1.columns, df1.mean(), yerr=errs_df, linestyle='None', marker='None', markersize=2, elinewidth=9, color='black', alpha=0.2)\n",
    "plt.errorbar(df1.columns, df1.mean(), yerr=errs_df, linestyle='None', marker='_', markersize=9, elinewidth=0, color='black', alpha=0.2)\n",
    "\n",
    "errs_sim_df = sim_df.apply(lambda x: percentile_confidence_interval(x), axis=0)\n",
    "plt.plot(sim_df.columns, sim_df.mean(), linestyle='None', marker='o', color='cornflowerblue')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"change in dF/F\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"posterior_full_comparison.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the posteriors\n",
    "simulation_results = np.array([map_estimate[\"experiment2\"]])\n",
    "\n",
    "simulation_results_mean = np.mean(simulation_results, axis=0)\n",
    "# simulation_results_conf = np.percentile(simulation_results, [2.5, 97.5], axis=0)\n",
    "\n",
    "deviation = np.std(data2, axis=0) / np.sqrt(data2.shape[0])\n",
    "experiment_conf = data2_means + 1.96 * np.array([-deviation, deviation])\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize=(2.5,2))\n",
    "axs.plot(time, data2_means, label=\"Experimental data\", alpha=0.2, color='black')\n",
    "axs.fill_between(time, experiment_conf[0], experiment_conf[1], alpha=0.2, color='black')\n",
    "axs.plot(time, simulation_results_mean, label=\"Model prediction\", color='cornflowerblue')\n",
    "# axs.fill_between(time, simulation_results_conf[0], simulation_results_conf[1], alpha=0.2, color='cornflowerblue')\n",
    "axs.set_xlabel(\"Time [s]\")\n",
    "axs.set_ylabel(\"Flourescence increase\")\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(\"exhaustion_comparison.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample the model\n",
    "trace = pm.sample(\n",
    "    model=model,\n",
    "    tune=400,\n",
    "    draws=1000,\n",
    "    cores=2,\n",
    "    nuts_sampler_kwargs={\"nuts_kwargs\": {\"max_tree_depth\": 6}},\n",
    "    nuts_sampler=\"numpyro\",\n",
    "    target_accept=0.8,\n",
    ")\n",
    "\n",
    "# save the trace\n",
    "az.to_netcdf(trace, \"trace_powerlaw.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trace`\n",
    "trace = az.from_netcdf(\"trace_powerlaw.nc\")\n",
    "# trace_all = trace\n",
    "trace = trace.sel(chain=[1])\n",
    "az.rhat(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the posterior\n",
    "sim_df = pd.DataFrame()\n",
    "for condition in conditions:\n",
    "    depletiontime, pausetime = condition\n",
    "    condition_name = \"{}_{}\".format(fm(depletiontime), fm(pausetime))\n",
    "    sim_df[condition_name] = trace.posterior[condition_name].to_numpy().flatten()\n",
    "\n",
    "fig = plt.figure(figsize=(3.5,2.8))\n",
    "ax = fig.subplots(1,1)\n",
    "\n",
    "# offset points\n",
    "import matplotlib.transforms as transforms\n",
    "offset = lambda p: transforms.ScaledTranslation(p/72.,0, fig.dpi_scale_trans)\n",
    "trans = ax.transData\n",
    "\n",
    "# remove the right and top and bottom spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "errs_df = df1.apply(lambda x: bootstrap_confidence_interval(x), axis=0)\n",
    "plt.errorbar(df1.columns, df1.mean(), yerr=errs_df, linestyle='None', marker='None', markersize=2, elinewidth=9, color='black', alpha=0.2)\n",
    "plt.errorbar(df1.columns, df1.mean(), yerr=errs_df, linestyle='None', marker='_', markersize=9, elinewidth=0, color='black', alpha=0.2)\n",
    "\n",
    "errs_sim_df = sim_df.apply(lambda x: percentile_confidence_interval(x), axis=0)\n",
    "plt.errorbar(sim_df.columns, sim_df.mean(), yerr=errs_sim_df, linestyle='None', marker='o', color='cornflowerblue')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"change in dF/F\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"posterior_GLM_exp1.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the posteriors\n",
    "simulation_results = trace.posterior[\"experiment2\"].to_numpy().reshape(-1, data2.shape[1])\n",
    "\n",
    "simulation_results_mean = np.mean(simulation_results, axis=0)\n",
    "simulation_results_conf = np.percentile(simulation_results, [2.5, 97.5], axis=0)\n",
    "\n",
    "deviation = np.std(data2, axis=0) / np.sqrt(data2.shape[0])\n",
    "experiment_conf = data2_means + 1.96 * np.array([-deviation, deviation])\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize=(2.5,2))\n",
    "axs.plot(time, data2_means, label=\"Experimental data\", alpha=0.2, color='black')\n",
    "axs.fill_between(time, experiment_conf[0], experiment_conf[1], alpha=0.2, color='black')\n",
    "axs.plot(time, simulation_results_mean, label=\"Model prediction\", color='cornflowerblue')\n",
    "axs.fill_between(time, simulation_results_conf[0], simulation_results_conf[1], alpha=0.2, color='cornflowerblue')\n",
    "axs.set_xlabel(\"Time [s]\")\n",
    "axs.set_ylabel(\"Flourescence increase\")\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "# axs.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(\"posterior_GLM_exp2.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cont(prior, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    samples = pm.draw(prior, draws=1000)\n",
    "    x = np.linspace(np.min(samples), np.max(samples), 1000)\n",
    "    ax.plot(x, np.exp(pm.logp(prior,x)).eval(), color='gray')\n",
    "    return ax\n",
    "\n",
    "condition_names = [\"{}_{}\".format(fm(condition[0]), fm(condition[1])) for condition in conditions] + [\"experiment2\"]\n",
    "\n",
    "name_dict = {\n",
    "    \"alpha1\": r\"$\\alpha$\",\n",
    "    \"b1\": r\"$b^{(1)}$\",\n",
    "    \"b2\": r\"$b^{(2)}$\",\n",
    "    \"kappa01\": r\"$\\log\\kappa_0^{(1)}$\",\n",
    "    \"kappa02\": r\"$\\log\\kappa_0^{(2)}$\",\n",
    "    \"observation_factor1\": r\"$\\alpha_{obs}^{(1)}$\",\n",
    "    \"error_model\": r\"$\\sigma_{obs}$\",\n",
    "    \"error_model1\": r\"$\\sigma_{obs}^{(1)}$\",\n",
    "    \"error_model2\": r\"$\\sigma_{obs}^{(2)}$\",\n",
    "    \"observation_factor2\": r\"$\\alpha_{obs}^{(2)}$\",\n",
    "}\n",
    "\n",
    "# for each variable plot prior and posterior\n",
    "names = [var.name for var in model.unobserved_RVs]\n",
    "fl = lambda name: not any([condition_name in name for condition_name in condition_names])\n",
    "names = list(filter(fl, names))\n",
    "\n",
    "sidelength = int(np.ceil(np.sqrt(len(names))))\n",
    "fig, axs = plt.subplots(sidelength, sidelength, figsize=(sidelength*2.5, sidelength*2));\n",
    "axs = axs.flatten()\n",
    "\n",
    "for name, i in zip(names, range(len(names))):\n",
    "    ax = axs[i]\n",
    "\n",
    "    pm.plot_posterior(trace, var_names=name, color='cornflowerblue', ax=ax)\n",
    "    ax.set_title(name_dict[name], fontdict={'fontsize': 15})\n",
    "    # plot prior\n",
    "    prior = model[name]\n",
    "    try:\n",
    "        plot_cont(prior, ax=ax)\n",
    "    except:\n",
    "        pass\n",
    "    # scale to posterior\n",
    "    ax.set_xlim((np.min(trace.posterior[name]), np.max(trace.posterior[name])))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"posterior_GLM.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(az.summary(trace))\n",
    "# keys = list(const_args_var.keys())\n",
    "# keys = [k.lower() for k in keys]\n",
    "# az.plot_forest(trace, var_names=keys, combined=True, hdi_prob=0.95, transform=lambda x: np.log10(x))\n",
    "# az.plot_forest(trace, var_names=[\"error_model\"], combined=True, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    if not \"log_likelihood\" in trace._groups:\n",
    "        log_likelihood = pm.compute_log_likelihood(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.to_netcdf(trace, \"trace_powerlaw_with_likelihood.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
